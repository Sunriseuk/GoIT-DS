{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'surprise'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m \u001b[39mimport\u001b[39;00m accuracy, Dataset, SVD, SVDpp, NMF\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m train_test_split\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39msurprise\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodel_selection\u001b[39;00m \u001b[39mimport\u001b[39;00m cross_validate\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'surprise'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import accuracy, Dataset, SVD, SVDpp, NMF\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise.model_selection import cross_validate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset ml-100k could not be found. Do you want to download it? [Y/n] Trying to download dataset from https://files.grouplens.org/datasets/movielens/ml-100k.zip...\n",
      "Done! Dataset ml-100k has been saved to C:\\Users\\User/.surprise_data/ml-100k\n"
     ]
    }
   ],
   "source": [
    "data = Dataset.load_builtin(name='ml-100k', prompt=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark = []\n",
    "algorithms = [SVD(), SVDpp(), NMF()]\n",
    "\n",
    "for algorithm in algorithms:\n",
    "    results = cross_validate(algorithm, data, measures=[\n",
    "                             'RMSE'], cv=5, verbose=False)\n",
    "    tmp = pd.DataFrame.from_dict(results).mean(axis=0)\n",
    "    tmp = pd.concat([pd.Series([str(algorithm).split(\n",
    "        ' ')[0].split('.')[-1]], index=['Algorithm']), tmp])\n",
    "    benchmark.append(tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "surprise_results = pd.DataFrame(benchmark).set_index(\n",
    "    'Algorithm').sort_values('test_rmse')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_rmse</th>\n",
       "      <th>fit_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Algorithm</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>SVDpp</th>\n",
       "      <td>0.919538</td>\n",
       "      <td>16.109844</td>\n",
       "      <td>3.380188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVD</th>\n",
       "      <td>0.935677</td>\n",
       "      <td>0.977418</td>\n",
       "      <td>0.153744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NMF</th>\n",
       "      <td>0.963889</td>\n",
       "      <td>1.389467</td>\n",
       "      <td>0.117471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           test_rmse   fit_time  test_time\n",
       "Algorithm                                 \n",
       "SVDpp       0.919538  16.109844   3.380188\n",
       "SVD         0.935677   0.977418   0.153744\n",
       "NMF         0.963889   1.389467   0.117471"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surprise_results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 0.9209\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9209044899882067"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset, testset = train_test_split(data, test_size=0.25)\n",
    "algo = SVDpp()\n",
    "algo.fit(trainset)\n",
    "predictions = algo.test(testset)\n",
    "\n",
    "accuracy.rmse(predictions)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Додаткове завдання\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import optimize\n",
    "from scipy.io import loadmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids = 'movie_ids.txt'\n",
    "movies_mat = 'movies.mat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizeRatings(Y, R):\n",
    "    m, n = Y.shape\n",
    "    Ymean = np.zeros(m)\n",
    "    Ynorm = np.zeros(Y.shape)\n",
    "\n",
    "    for i in range(m):\n",
    "        idx = R[i, :] == 1\n",
    "        Ymean[i] = np.mean(Y[i, idx])\n",
    "        Ynorm[i, idx] = Y[i, idx] - Ymean[i]\n",
    "\n",
    "    return Ynorm, Ymean\n",
    "\n",
    "\n",
    "def loadMovieList():\n",
    "    # Read the fixed movieulary list\n",
    "    with open(movie_ids,  encoding='ISO-8859-1') as fid:\n",
    "        movies = fid.readlines()\n",
    "\n",
    "    movieNames = []\n",
    "    for movie in movies:\n",
    "        parts = movie.split()\n",
    "        movieNames.append(' '.join(parts[1:]).strip())\n",
    "    return movieNames\n",
    "\n",
    "\n",
    "def computeNumericalGradient(J, theta, e=1e-4):\n",
    "    numgrad = np.zeros(theta.shape)\n",
    "    perturb = np.diag(e * np.ones(theta.shape))\n",
    "    for i in range(theta.size):\n",
    "        loss1, _ = J(theta - perturb[:, i])\n",
    "        loss2, _ = J(theta + perturb[:, i])\n",
    "        numgrad[i] = (loss2 - loss1)/(2*e)\n",
    "    return numgrad\n",
    "\n",
    "\n",
    "def checkCostFunction(cofiCostFunc, lambda_=0.):\n",
    "    # Create small problem\n",
    "    X_t = np.random.rand(4, 3)\n",
    "    Theta_t = np.random.rand(5, 3)\n",
    "\n",
    "    # Zap out most entries\n",
    "    Y = np.dot(X_t, Theta_t.T)\n",
    "    Y[np.random.rand(*Y.shape) > 0.5] = 0\n",
    "    R = np.zeros(Y.shape)\n",
    "    R[Y != 0] = 1\n",
    "\n",
    "    # Run Gradient Checking\n",
    "    X = np.random.randn(*X_t.shape)\n",
    "    Theta = np.random.randn(*Theta_t.shape)\n",
    "    num_movies, num_users = Y.shape\n",
    "    num_features = Theta_t.shape[1]\n",
    "\n",
    "    params = np.concatenate([X.ravel(), Theta.ravel()])\n",
    "    numgrad = computeNumericalGradient(\n",
    "        lambda x: cofiCostFunc(x, Y, R, num_users, num_movies, num_features, lambda_), params)\n",
    "\n",
    "    cost, grad = cofiCostFunc(params, Y, R, num_users,num_movies, num_features, lambda_)\n",
    "\n",
    "    print(np.stack([numgrad, grad], axis=1))\n",
    "    print('\\nThe above two columns you get should be very similar.'\n",
    "          '(Left-Your Numerical Gradient, Right-Analytical Gradient)')\n",
    "\n",
    "    diff = np.linalg.norm(numgrad-grad)/np.linalg.norm(numgrad+grad)\n",
    "    print('If your cost function implementation is correct, then '\n",
    "          'the relative difference will be small (less than 1e-9).')\n",
    "    print('\\nRelative Difference: %g' % diff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1682"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = loadMovieList()\n",
    "len(names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average rating for movie 1601 ( M. Butterfly (1993) ): 4.904560 / 5\n"
     ]
    }
   ],
   "source": [
    "\n",
    "data = loadmat(movies_mat)\n",
    "Y, R = data['Y'], data['R']\n",
    "\n",
    "print('Average rating for movie 1601 (',names[1400] ,'): %f / 5' %\n",
    "      np.mean(Y[180, R[1400, :]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cofiCostFunc(params, Y, R, num_users, num_movies,\n",
    "                      num_features, lambda_=0.0):\n",
    "    # Unfold the U and W matrices from params\n",
    "    X = params[:num_movies*num_features].reshape(num_movies, num_features)\n",
    "    Theta = params[num_movies*num_features:].reshape(num_users, num_features)\n",
    "\n",
    "    # You need to return the following values correctly\n",
    "    J = 0\n",
    "    X_grad = np.zeros(X.shape)\n",
    "    Theta_grad = np.zeros(Theta.shape)\n",
    "\n",
    "    J = (1 / 2) * np.sum(np.square((X.dot(Theta.T) - Y) * R)) + (lambda_ / 2) * np.sum(np.square(X)) + \\\n",
    "                                                                (lambda_ / 2) * np.sum(np.square(Theta))\n",
    "    \n",
    "    for i in range(R.shape[0]):\n",
    "        \n",
    "        idx = np.where(R[i, :] == 1)[0]\n",
    "        Theta_temp = Theta[idx, :]\n",
    "        Y_temp = Y[i, idx]\n",
    "        X_grad[i, :] = np.dot(np.dot(X[i, :], Theta_temp.T) - Y_temp, Theta_temp) + lambda_ * X[i, :]\n",
    "        \n",
    "    for j in range(R.shape[1]):\n",
    "        \n",
    "        idx = np.where(R[:, j] == 1)[0]\n",
    "        X_temp = X[idx, :]\n",
    "        Y_temp = Y[idx, j]\n",
    "        Theta_grad[j, :] = np.dot(np.dot(X_temp, Theta[j, :]) - Y_temp, X_temp) + lambda_ * Theta[j, :]\n",
    "    \n",
    "    grad = np.concatenate([X_grad.ravel(), Theta_grad.ravel()])\n",
    "    return J, grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 9.63355895e-01  9.63355895e-01]\n",
      " [ 3.82458375e-01  3.82458375e-01]\n",
      " [ 1.89468096e+00  1.89468096e+00]\n",
      " [ 1.99989831e+00  1.99989831e+00]\n",
      " [-3.52601200e+00 -3.52601200e+00]\n",
      " [-6.25417787e+00 -6.25417787e+00]\n",
      " [ 2.04001028e-01  2.04001028e-01]\n",
      " [-3.25317988e+00 -3.25317988e+00]\n",
      " [-3.14062405e+00 -3.14062405e+00]\n",
      " [-4.02625501e+00 -4.02625501e+00]\n",
      " [-4.60809805e+00 -4.60809805e+00]\n",
      " [ 2.29418475e-01  2.29418475e-01]\n",
      " [-3.25295539e+00 -3.25295539e+00]\n",
      " [-6.19889106e-01 -6.19889106e-01]\n",
      " [ 1.46498118e+00  1.46498118e+00]\n",
      " [-1.17467230e+00 -1.17467230e+00]\n",
      " [-1.91882696e+00 -1.91882696e+00]\n",
      " [-8.68432339e-01 -8.68432339e-01]\n",
      " [-2.41858048e+00 -2.41858048e+00]\n",
      " [ 4.62270383e+00  4.62270383e+00]\n",
      " [ 7.43647099e+00  7.43647099e+00]\n",
      " [-4.97316586e-01 -4.97316586e-01]\n",
      " [-4.92409967e-03 -4.92409966e-03]\n",
      " [ 2.28596628e+00  2.28596628e+00]\n",
      " [ 4.28078851e+00  4.28078851e+00]\n",
      " [ 3.23882654e+00  3.23882654e+00]\n",
      " [-2.41669293e+00 -2.41669293e+00]]\n",
      "\n",
      "The above two columns you get should be very similar.(Left-Your Numerical Gradient, Right-Analytical Gradient)\n",
      "If your cost function implementation is correct, then the relative difference will be small (less than 1e-9).\n",
      "\n",
      "Relative Difference: 2.51935e-12\n"
     ]
    }
   ],
   "source": [
    "checkCostFunction(cofiCostFunc, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "movieList = loadMovieList()\n",
    "\n",
    "#  Before we will train the collaborative filtering model, we will first\n",
    "#  add ratings that correspond to a new user that we just observed. This\n",
    "#  part of the code will also allow you to put in your own ratings for the\n",
    "#  movies in our dataset!\n",
    "n_m = len(movieList)\n",
    "#  Initialize my ratings\n",
    "my_ratings = np.zeros(n_m)\n",
    "# We have selected a few movies we liked / did not like and the ratings we\n",
    "# gave are as follows:\n",
    "my_ratings[0] = 4\n",
    "my_ratings[97] = 2\n",
    "my_ratings[6] = 2\n",
    "my_ratings[11]= 5\n",
    "my_ratings[53] = 4\n",
    "my_ratings[63] = 5\n",
    "my_ratings[364] = 2\n",
    "my_ratings[68] = 5\n",
    "my_ratings[182] = 4\n",
    "my_ratings[225] = 5\n",
    "my_ratings[354] = 1\n",
    "my_ratings[22] = 5\n",
    "my_ratings[124] = 5\n",
    "my_ratings[54] = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Local\\Temp\\ipykernel_3760\\1892729221.py:23: DeprecationWarning: 'maxiter' has been deprecated in favor of 'maxfun' and will be removed in SciPy 1.11.0.\n",
      "  res = optimize.minimize(lambda x: cofiCostFunc(x, Ynorm, R, num_users,\n"
     ]
    }
   ],
   "source": [
    "#  Add our own ratings to the data matrix\n",
    "Y = np.hstack([my_ratings[:, None], Y])\n",
    "R = np.hstack([(my_ratings > 0)[:, None], R])\n",
    "\n",
    "#  Normalize Ratings\n",
    "Ynorm, Ymean = normalizeRatings(Y, R)\n",
    "\n",
    "#  Useful Values\n",
    "num_movies, num_users = Y.shape\n",
    "num_features = 7\n",
    "\n",
    "# Set Initial Parameters (Theta, X)\n",
    "X = np.random.randn(num_movies, num_features)\n",
    "Theta = np.random.randn(num_users, num_features)\n",
    "\n",
    "initial_parameters = np.concatenate([X.ravel(), Theta.ravel()])\n",
    "\n",
    "# Set options for scipy.optimize.minimize\n",
    "options = {'maxiter': 100}\n",
    "\n",
    "# Set Regularization\n",
    "lambda_ = 10\n",
    "res = optimize.minimize(lambda x: cofiCostFunc(x, Ynorm, R, num_users,\n",
    "                                               num_movies, num_features, lambda_),\n",
    "                        initial_parameters,\n",
    "                        method='TNC',\n",
    "                        jac=True,\n",
    "                        options=options)\n",
    "theta = res.x\n",
    "\n",
    "# Unfold the returned theta back into U and W\n",
    "X = theta[:num_movies*num_features].reshape(num_movies, num_features)\n",
    "Theta = theta[num_movies*num_features:].reshape(num_users, num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top recommendations for you:\n",
      "----------------------------\n",
      "Predicting rating 5.0 for movie Santa with Muscles (1996)\n",
      "Predicting rating 5.0 for movie Someone Else's America (1995)\n",
      "Predicting rating 5.0 for movie Great Day in Harlem, A (1994)\n",
      "Predicting rating 5.0 for movie They Made Me a Criminal (1939)\n",
      "Predicting rating 5.0 for movie Marlene Dietrich: Shadow and Light (1996)\n",
      "Predicting rating 5.0 for movie Entertaining Angels: The Dorothy Day Story (1996)\n",
      "Predicting rating 5.0 for movie Saint of Fort Washington, The (1993)\n",
      "Predicting rating 5.0 for movie Prefontaine (1997)\n",
      "Predicting rating 5.0 for movie Star Kid (1997)\n",
      "Predicting rating 5.0 for movie Aiqing wansui (1994)\n",
      "Predicting rating 4.6 for movie Pather Panchali (1955)\n",
      "Predicting rating 4.6 for movie Shawshank Redemption, The (1994)\n",
      "Predicting rating 4.6 for movie Schindler's List (1993)\n",
      "Predicting rating 4.5 for movie Star Wars (1977)\n",
      "Predicting rating 4.5 for movie It's a Wonderful Life (1946)\n",
      "\n",
      "Original ratings provided:\n",
      "--------------------------\n",
      "Rated 4 for Toy Story (1995)\n",
      "Rated 2 for Twelve Monkeys (1995)\n",
      "Rated 5 for Usual Suspects, The (1995)\n",
      "Rated 5 for Taxi Driver (1976)\n",
      "Rated 4 for Outbreak (1995)\n",
      "Rated 2 for Professional, The (1994)\n",
      "Rated 5 for Shawshank Redemption, The (1994)\n",
      "Rated 5 for Forrest Gump (1994)\n",
      "Rated 2 for Silence of the Lambs, The (1991)\n",
      "Rated 5 for Phenomenon (1996)\n",
      "Rated 4 for Alien (1979)\n",
      "Rated 5 for Die Hard 2 (1990)\n",
      "Rated 1 for Sphere (1998)\n",
      "Rated 2 for Powder (1995)\n"
     ]
    }
   ],
   "source": [
    "# Make recommendations by computing the predictions matrix\n",
    "p = np.dot(X, Theta.T)\n",
    "my_predictions = p[:, 0] + Ymean\n",
    "\n",
    "movieList = loadMovieList()\n",
    "\n",
    "ix = np.argsort(my_predictions)[::-1]\n",
    "\n",
    "print('Top recommendations for you:')\n",
    "print('----------------------------')\n",
    "for i in range(15):\n",
    "    j = ix[i]\n",
    "    print('Predicting rating %.1f for movie %s' % (my_predictions[j], movieList[j]))\n",
    "\n",
    "print('\\nOriginal ratings provided:')\n",
    "print('--------------------------')\n",
    "for i in range(len(my_ratings)):\n",
    "    if my_ratings[i] > 0:\n",
    "        print('Rated %d for %s' % (my_ratings[i], movieList[i]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
